WSS = sapply(k, function(k) {kmeans(scaled_df_no_outliers, centers=k)$tot.withinss})
plot(k, WSS, type="l", xlab= "Number of k clusters", ylab="Within-clusters sum of squares")
# Gap statistics
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 10, K.max = 10, B = 50)
gap_clusters <- maxSE(gap_result, method="Tibs2001SEmax")$Cluster[1]
print(gap_clusters)
# Gap statistics
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 20, K.max = 10, B = 50)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 20, K.max = 2, B = 20)
print(gap_clusters)
gap_clusters <- maxSE(gap_result, method="Tibs2001SEmax")$Cluster[1]
print(gap_clusters)
print(gap_result)
# Print results
cat("Number of clusters determined by NBclust: ", nbclust_clusters, "\n")
cat("Number of clusters determined by Elbow method: ", elbow_clusters, "\n")
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 20, K.max = 10, B = 20)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 10, B = 50)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 8, B = 50)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 5, B = 50)
print(gap_result)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 7, B = 50)
print(gap_result)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 10, B = 50)
print(gap_result)
# Gap statistics
set.seed(42)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 10, B = 50)
print(gap_result)
# Get optimal k value
optimal_k <- gap_result$optimalK
print(optimal_k)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 25, K.max = 10, B = 50)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 50, K.max = 10, B = 100)
print(gap_result)
# Get optimal k value
optimal_k <- gap_result$optimalK
print(optimal_k)
# Silhouette method method
silhouette_result <- silhouette_samples(scaled_df_no_outliers, kmeans(nbclust_clusters, scaled_df_no_outliers)$cluster)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k)
# Perform k-means clustering with the most favoured k from automated tools
k <- nbclust_clusters
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k)
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
BSS <- sum(kmeans_result$betweenss)
WSS <- sum(kmeans_result$tot.withinss)
# Calculate ratio of BSS over TSS
TSS <- BSS + WSS
BSS_ratio <- BSS / TSS
# Silhouette plot
silhouette_plot <- silhouette_plot(scaled_data, kmeans_result$cluster)
# Perform k-means clustering with the most favoured k from automated tools
k <- nbclust_clusters
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k)
# Print results
cat("Number of clusters determined by NBclust: ", nbclust_clusters, "\n")
cat("Number of clusters determined by Elbow method: ", elbow_clusters, "\n")
cat("Number of clusters determined by Gap statistics: ", gap_clusters, "\n")
cat("Number of clusters determined by Silhouette method: ", silhouette_clusters, "\n")
cat("K-means clustering results: \n")
cat("Cluster Centers: \n", kmeans_result$centers, "\n")
cat("Between Cluster Sum of Squares (BSS): ", BSS, "\n")
cat("Within Cluster Sum of Squares (WSS): ", WSS, "\n")
cat("BSS/TSS Ratio: ", BSS_ratio, "\n")
cat("Average Silhouette Width: ", avg_silhouette_width, "\n")
# Plot Silhouette plot
plot(silhouette_plot)
# Perform k-means clustering with different values of k
kmax <- 10
kmeans_results <- list()
for (k in 2:kmax) {
kmeans_results[[as.character(k)]] <- kmeans(data, centers = k, nstart = 25)
}
# Perform k-means clustering with different values of k
kmax <- 10
kmeans_results <- list()
for (k in 2:kmax) {
kmeans_results[[as.character(k)]] <- kmeans(scaled_df_no_outliers, centers = k, nstart = 25)
}
print(kmeans_results)
print(kmeans_results)
gap_result <- clusGap(scaled_df_no_outliers, FUNcluster = kmeans, nstart = 50, K.max = kmax)
print(gap_result)
# Get optimal k value
optimal_k <- gap_result$optimalK
print(optimal_k)
# Silhouette method method
fviz_nbclust(iris_transform, kmeans, method = 'silhouette')
# Silhouette method method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'silhouette')
print(silhouette_clusters)
# Gap statistics method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'gap_stat')
# Silhouette method method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'silhouette')
# Gap statistics method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'gap_stat')
# Perform k-means clustering with the most favoured k from automated tools
k <- nbclust_clusters
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k)
# Silhouette method method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'silhouette')
# Gap statistics method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'gap_stat')
# Perform k-means clustering with the most favoured k from automated tools
k <- nbclust_clusters
print(k)
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'wss')
WSS = sapply(k, function(k) {kmeans(scaled_df_no_outliers, centers=k)$tot.withinss})
plot(k, WSS, type="l", xlab= "Number of k clusters", ylab="Within-clusters sum of squares")
# Elbow method
k = 2:10
set.seed(42)
WSS = sapply(k, function(k) {kmeans(scaled_df_no_outliers, centers=k)$tot.withinss})
plot(k, WSS, type="l", xlab= "Number of k clusters", ylab="Within-clusters sum of squares")
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'wss')
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
# Perform k-means clustering with the most favoured k from automated tools
k <- nbclust_clusters
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
nbclust_result <- NbClust(scaled_df_no_outliers, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index="all")
# Automated tools for determining number of cluster centers
# NBclust methods
library(NbClust)
set.seed(42)
nbclust_result <- NbClust(scaled_df_no_outliers, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index="all")
# Perform k-means clustering with the most favoured k from automated tools
k = 9
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
# Perform k-means clustering with the most favoured k from automated tools
k = 2
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
# Perform k-means clustering with the most favoured k from automated tools
k = 3
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
# Perform k-means clustering with the most favoured k from automated tools
k = 9
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
# Perform k-means clustering with the most favoured k from automated tools
k = 2
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
# Perform k-means clustering with the most favored k from automated tools
k = 9
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
# Perform k-means clustering with the most favored k from automated tools
k = 10
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
# Perform k-means clustering with the most favored k from automated tools
k = 2
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
fviz_cluster(kmeans_result, data = scaled_df_no_outliers, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Visualize
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
fviz_cluster(kmeans_result, data = scaled_df_no_outliers, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
wss = kmeans_result$tot.withinss
bss = kmeans_result$betweenss
print("WSS:" + wss)
print("WSS:", wss)
print(wss)
bss
sil <- silhouette(kmeans_result$cluster, dist(scaled_df_no_outliers))
fviz_silhouette(sil)
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
WSS = kmeans_result$tot.withinss
BSS = kmeans_result$betweenss
WSS
BSS
# Calculate ratio of BSS over TSS
TSS <- BSS + WSS
BSS_ratio <- BSS / TSS
BSS_ratio
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
WSS = kmeans_result$tot.withinss
BSS = kmeans_result$betweenss
WSS
BSS
# Calculate ratio of BSS over TSS
TSS <- BSS + WSS
# Calculate the BSS/TSS Ratio
BSS_ratio <- BSS / TSS
BSS_ratio
cat("BSS/TSS Ratio:", BSS_ratio)
BSS = kmeans_result$betweenss
cat("WSS:", WSS)
cat("BSS:", BSS)
# Calculate ratio of BSS over TSS
TSS <- BSS + WSS
cat("TSS:", TSS)
# Calculate the BSS/TSS Ratio
BSS_ratio <- BSS / TSS
cat("BSS/TSS Ratio:", BSS_ratio)
# Silhouette plot
sil <- silhouette(kmeans_result$cluster, dist(scaled_df_no_outliers))
fviz_silhouette(sil)
# Perform PCA on the scaled dataset
pca <- prcomp(scaled_df_no_outliers)
# Extract eigenvalues and eigenvectors
eigenvalues <- pca$sdev^2
eigenvectors <- pca$rotation
# Print eigenvalues and eigenvectors
cat("Eigenvalues:\n")
print(eigenvalues)
cat("\nEigenvectors:\n")
print(eigenvectors)
# Calculate cumulative score per principal component
cumulative_score <- cumsum(pca$sdev^2 / sum(pca$sdev^2) * 100)
# Print cumulative score per principal component
cat("\nCumulative Score per Principal Component:\n")
print(cumulative_score)
# Choose principal components with cumulative score > 92%
chosen_pcs <- which(cumulative_score > 92)
cat("\nChosen Principal Components:\n")
print(chosen_pcs)
# Create a new dataset with transformed principal components
df_pcs <- as.data.frame(pca$x[, chosen_pcs])
colnames(df_pcs) <- paste0("PC", chosen_pcs)
# Print the transformed dataset
cat("\nTransformed Dataset with Principal Components:\n")
print(df_pcs)
print(chosen_pcs)
print(df_pcs)
View(df_pcs)
## Part F
# Automated tools for determining number of cluster centers
# NBclust methods
library(NbClust)
set.seed(42)
nbclust_result_pca <- NbClust(df_pcs, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index="all")
# Elbow method
#k = 2:10
#set.seed(42)
#WSS = sapply(k, function(k) {kmeans(scaled_df_no_outliers, centers=k)$tot.withinss})
#plot(k, WSS, type="l", xlab= "Number of k clusters", ylab="Within-clusters sum of squares")
fviz_nbclust(df_pcs, kmeans, method = 'wss')
# Gap statistics method
fviz_nbclust(df_pcs, kmeans, method = 'gap_stat')
# Silhouette method method
fviz_nbclust(df_pcs, kmeans, method = 'silhouette')
# Perform k-means clustering with the most favored k from automated tools
k = 7
print(k)
kmeans_result_pca <- kmeans(df_pcs, centers = k, nstart=10)
kmeans_result_pca
# Visualize
fviz_cluster(kmeans_result_pca, data = df_pcs)
fviz_cluster(kmeans_result_pca, data = df_pcs, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
WSS_pca = kmeans_result_pca$tot.withinss
BSS_pca = kmeans_result_pca$betweenss
cat("WSS:", WSS_pca)
cat("BSS:", BSS_pca)
# Calculate ratio of BSS over TSS
TSS_pca <- BSS_pca + WSS_pca
cat("TSS:", TSS)
# Calculate the BSS/TSS Ratio
BSS_ratio_pca <- BSS / TSS
cat("BSS/TSS Ratio:", BSS_ratio_pca)
# Silhouette plot
sil <- silhouette(kmeans_result_pca$cluster, dist(df_pcs))
fviz_silhouette(sil)
install.packages("fpc")
## Part I
# Calculate cluster membership for each observation
cluster_membership <- kmeans_result_pca$cluster
calinski_harabasz <- cluster.stats(df_pcs, cluster_membership)$ch  # Calculate Calinski-Harabasz Index
library(fpc)  # Load fpc package for Calinski-Harabasz Index
library(ggplot2)  # Load ggplot2 package for data visualization
# Calculate Calinski-Harabasz Index
calinski_harabasz <- cluster.stats(df_pcs, cluster_membership)$ch  # Calculate Calinski-Harabasz Index
## Part I
# Calculate cluster membership for each observation
cluster_membership <- kmeans_result_pca$cluster
# Calculate Calinski-Harabasz Index
calinski_harabasz <- cluster.stats(df_pcs, cluster_membership)$ch  # Calculate Calinski-Harabasz Index
# Calculate Calinski-Harabasz Index
calinski_harabasz <- cluster.stats(dist_matrix, cluster_membership)$ch  # Calculate Calinski-Harabasz Index
## Part I
# Calculate cluster membership for each observation
cluster_membership <- kmeans_result_pca$cluster
# Calculate dissimilarity matrix from the transformed dataset
dist_matrix <- dist(df_pcs)
# Calculate Calinski-Harabasz Index
calinski_harabasz <- cluster.stats(dist_matrix, cluster_membership)$ch  # Calculate Calinski-Harabasz Index
# Print Calinski-Harabasz Index
cat("Calinski-Harabasz Index:", calinski_harabasz, "\n")
df_plot <- cbind(df_pcs, cluster = as.factor(cluster_membership))  # Combine transformed dataset with cluster membership
ggplot(df_plot, aes(x = PC1, y = PC2, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering with PCA",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Cluster")
# Print Calinski-Harabasz Index
cat("Calinski-Harabasz Index:", calinski_harabasz, "\n")
# Plot the clusters using the first two principal components
library(ggplot2)  # Load ggplot2 package for data visualization
df_plot <- cbind(df_pcs, cluster = as.factor(cluster_membership))  # Combine transformed dataset with cluster membership
ggplot(df_plot, aes(x = PC1, y = PC2, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering with PCA",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Cluster")
ggplot(df_plot, aes_string(x = "PC1", y = "PC2", color = "cluster")) +
geom_point() +
labs(title = "K-means Clustering with PCA",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Cluster")
# Plot the clusters using the first two principal components
df_plot <- cbind(df_pcs, cluster = as.factor(cluster_membership))  # Combine transformed dataset with cluster membership
ggplot(df_plot, aes(x = PC1, y = PC2, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering with PCA",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Cluster")
# Create a new dataset with transformed principal components
df_pcs <- as.data.frame(pca$x[, chosen_pcs])
colnames(df_pcs) <- paste0("PC", chosen_pcs)
# Extract the principal components from the PCA result
df_pcs <- data.frame(pca$x)  # Create a data frame with the principal components
# Plot the clusters using the first two principal components
df_plot <- cbind(df_pcs, cluster = as.factor(cluster_membership))  # Combine transformed dataset with cluster membership
ggplot(df_plot, aes(x = PC1, y = PC2, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering with PCA",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Cluster")
print(chosen_pcs)
# Extract the principal components from the PCA result
df_pcs <- data.frame(pca$x)  # Create a data frame with the principal components
df_pcs
# Perform k-means clustering with the most favored k from automated tools
k = 3
print(k)
kmeans_result_pca <- kmeans(df_pcs, centers = k, nstart=10)
kmeans_result_pca
# Visualize
fviz_cluster(kmeans_result_pca, data = df_pcs)
fviz_cluster(kmeans_result_pca, data = df_pcs, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Perform k-means clustering with the most favored k from automated tools
k = 3
print(k)
kmeans_result_pca <- kmeans(df_pcs, centers = k, nstart=10)
kmeans_result_pca
# Visualize
fviz_cluster(kmeans_result_pca, data = df_pcs)
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
WSS_pca = kmeans_result_pca$tot.withinss
BSS_pca = kmeans_result_pca$betweenss
cat("WSS:", WSS_pca)
cat("BSS:", BSS_pca)
# Calculate ratio of BSS over TSS
TSS_pca <- BSS_pca + WSS_pca
cat("TSS:", TSS)
# Calculate the BSS/TSS Ratio
BSS_ratio_pca <- BSS / TSS
cat("BSS/TSS Ratio:", BSS_ratio_pca)
# Silhouette plot
sil <- silhouette(kmeans_result_pca$cluster, dist(df_pcs))
fviz_silhouette(sil)
# Outlier removal
z_scores <- apply(vehicles_no_outliers_scaled, 2, function(x) abs(scale(x, center = TRUE, scale = FALSE)))
# Outlier removal
z_scores <- apply(df_scaled, 2, function(x) abs(scale(x, center = TRUE, scale = FALSE)))
scaled_df_no_outliers <- df_scaled[rowSums(z_scores < 3) == ncol(df_scaled), ]
set.seed(42)
nbclust_result <- NbClust(scaled_df_no_outliers, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index="all")
# Elbow method
#k = 2:10
#set.seed(42)
#WSS = sapply(k, function(k) {kmeans(scaled_df_no_outliers, centers=k)$tot.withinss})
#plot(k, WSS, type="l", xlab= "Number of k clusters", ylab="Within-clusters sum of squares")
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'wss')
# Gap statistics method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'gap_stat')
# Silhouette method method
fviz_nbclust(scaled_df_no_outliers, kmeans, method = 'silhouette')
# Perform k-means clustering with the most favored k from automated tools
k = 2
print(k)
kmeans_result <- kmeans(scaled_df_no_outliers, centers = k, nstart=10)
kmeans_result
# Visualize
fviz_cluster(kmeans_result, data = scaled_df_no_outliers)
fviz_cluster(kmeans_result, data = scaled_df_no_outliers, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
WSS = kmeans_result$tot.withinss
BSS = kmeans_result$betweenss
cat("WSS:", WSS)
cat("BSS:", BSS)
# Calculate ratio of BSS over TSS
TSS <- BSS + WSS
cat("TSS:", TSS)
# Calculate the BSS/TSS Ratio
BSS_ratio <- BSS / TSS
cat("BSS/TSS Ratio:", BSS_ratio)
# Silhouette plot
sil <- silhouette(kmeans_result$cluster, dist(scaled_df_no_outliers))
fviz_silhouette(sil)
# Perform PCA on the scaled dataset
pca <- prcomp(scaled_df_no_outliers)
# Extract eigenvalues and eigenvectors
eigenvalues <- pca$sdev^2
eigenvectors <- pca$rotation
# Print eigenvalues and eigenvectors
cat("Eigenvalues:\n")
print(eigenvalues)
cat("\nEigenvectors:\n")
print(eigenvectors)
# Calculate cumulative score per principal component
cumulative_score <- cumsum(pca$sdev^2 / sum(pca$sdev^2) * 100)
# Print cumulative score per principal component
cat("\nCumulative Score per Principal Component:\n")
print(cumulative_score)
# Choose principal components with cumulative score > 92%
chosen_pcs <- which(cumulative_score > 92)
cat("\nChosen Principal Components:\n")
print(chosen_pcs)
# Extract the principal components from the PCA result
df_pcs <- data.frame(pca$x)  # Create a data frame with the principal components
df_pcs
# Print the transformed dataset
cat("\nTransformed Dataset with Principal Components:\n")
print(df_pcs)
## Part F
# Automated tools for determining number of cluster centers
# NBclust methods
set.seed(42)
nbclust_result_pca <- NbClust(df_pcs, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index="all")
# Elbow method
#k = 2:10
#set.seed(42)
#WSS = sapply(k, function(k) {kmeans(scaled_df_no_outliers, centers=k)$tot.withinss})
#plot(k, WSS, type="l", xlab= "Number of k clusters", ylab="Within-clusters sum of squares")
fviz_nbclust(df_pcs, kmeans, method = 'wss')
# Gap statistics method
fviz_nbclust(df_pcs, kmeans, method = 'gap_stat')
# Silhouette method method
fviz_nbclust(df_pcs, kmeans, method = 'silhouette')
# Perform k-means clustering with the most favored k from automated tools
k = 3
print(k)
kmeans_result_pca <- kmeans(df_pcs, centers = k, nstart=10)
kmeans_result_pca
# Visualize
fviz_cluster(kmeans_result_pca, data = df_pcs)
fviz_cluster(kmeans_result_pca, data = df_pcs, ellipse.type = "euclid",
star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal())
# Calculate the between_cluster_sums_of_squares (BSS) and within_cluster_sums_of_squares (WSS) indices
WSS_pca = kmeans_result_pca$tot.withinss
BSS_pca = kmeans_result_pca$betweenss
cat("WSS:", WSS_pca)
cat("BSS:", BSS_pca)
# Calculate ratio of BSS over TSS
TSS_pca <- BSS_pca + WSS_pca
cat("TSS:", TSS)
# Calculate the BSS/TSS Ratio
BSS_ratio_pca <- BSS / TSS
cat("BSS/TSS Ratio:", BSS_ratio_pca)
# Silhouette plot
sil <- silhouette(kmeans_result_pca$cluster, dist(df_pcs))
fviz_silhouette(sil)
## Part I
# Calculate cluster membership for each observation
cluster_membership <- kmeans_result_pca$cluster
# Calculate dissimilarity matrix from the transformed dataset
dist_matrix <- dist(df_pcs)
# Calculate Calinski-Harabasz Index
calinski_harabasz <- cluster.stats(dist_matrix, cluster_membership)$ch  # Calculate Calinski-Harabasz Index
# Print Calinski-Harabasz Index
cat("Calinski-Harabasz Index:", calinski_harabasz, "\n")
# Plot the clusters using the first two principal components
df_plot <- cbind(df_pcs, cluster = as.factor(cluster_membership))  # Combine transformed dataset with cluster membership
ggplot(df_plot, aes(x = PC1, y = PC2, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering with PCA",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Cluster")
